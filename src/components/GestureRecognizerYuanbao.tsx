import {useEffect, useRef, useState} from "react";
import {
    GestureRecognizer,
    FilesetResolver,
    DrawingUtils
} from "@mediapipe/tasks-vision";
import "../styles/GestureRecognizerYuanbao.css";
import EventBus from "@/js/eventBus";
import {MessageData} from "@/components/chat";
import {Message} from "@/components/stream-player-v2";
import {useChat, useDataChannel} from "@livekit/components-react";
import {DataPacket_Kind, Participant} from "livekit-client";


export function GestureRecognizerComponent() {
    //const [gestureRecognizer, setGestureRecognizer] = useState<GestureRecognizer | null>(null);
    const [webcamRunning, setWebcamRunning] = useState(false);
    const [gestureResult, setGestureResult] = useState<string>("");
    //const [canvasReady, setCanvasReady] = useState(false); // æ–°å¢çŠ¶æ€
    const webcamRef = useRef<HTMLVideoElement>(null);
    const canvasRef = useRef<HTMLCanvasElement>(null);
    const containerRef = useRef<HTMLDivElement>(null); // æ–°å¢å®¹å™¨å¼•ç”¨
    const lastVideoTimeRef = useRef(-1);
    const requestRef = useRef<number>(0);
    const basePath = window.location.origin + "/";
    const modelPath = `${basePath}mediapipe/models/gesture_recognizer.task`;
    const [categoryName, setCategoryName] = useState(""); // è§†è§‰çŠ¶æ€
    //ä½¿ç”¨refæ¥å­˜å‚¨è¯†åˆ«å™¨å’Œç”»å¸ƒå¼•ç”¨
    const gestureRecognizerRef = useRef<GestureRecognizer | null>(null);
    const canvasReadyRef = useRef(false);


    const [encoder] = useState(() => new TextEncoder());
    const {send} = useDataChannel("reactions");
    const {send: sendChat} = useChat();

    const onSend = (emoji: string) => {
        send(encoder.encode(emoji), {kind: DataPacket_Kind.LOSSY});
        if (sendChat) {
            sendChat(emoji);
        }
    };


    // åˆå§‹åŒ–æ‰‹åŠ¿è¯†åˆ«å™¨
    const initializeGestureRecognizer = async () => {
        try {
            const vision = await FilesetResolver.forVisionTasks(
                `${basePath}mediapipe/vision`
            );

            // ç¡®ä¿ç”»å¸ƒå…ƒç´ å­˜åœ¨
            if (!canvasRef.current) {
                console.error("Canvas element not found during initialization");
                return;
            }

            // ç¡®ä¿ç”»å¸ƒæœ‰å°ºå¯¸
            if (canvasRef.current.width === 0 || canvasRef.current.height === 0) {
                console.warn("Canvas has zero dimensions, setting default size");
                canvasRef.current.width = 480;
                canvasRef.current.height = 360;
            }

            // å°è¯•è·å–ä¸Šä¸‹æ–‡ä»¥éªŒè¯ç”»å¸ƒæ˜¯å¦å¯ç”¨
            const testCtx = canvasRef.current.getContext("2d");
            if (!testCtx) {
                console.error("Failed to get 2D context during initialization");
                return;
            }

            const recognizer = await GestureRecognizer.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: modelPath,
                    delegate: "GPU"
                },
                runningMode: "VIDEO" as const,
            });
            gestureRecognizerRef.current = recognizer;
            //setGestureRecognizer(recognizer);
            console.log("æ‰‹åŠ¿è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ");
            canvasReadyRef.current = true;
            //setCanvasReady(true); // æ ‡è®°ç”»å¸ƒå·²å‡†å¤‡å¥½

        } catch (error) {
            console.error("åˆå§‹åŒ–æ‰‹åŠ¿è¯†åˆ«å™¨å¤±è´¥:", error);
            alert(`åˆå§‹åŒ–å¤±è´¥: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`);
        }
    };

    useEffect(() => {
        initializeGestureRecognizer().then(() => {
                if (!webcamRunning) {
                    enableCam();
                }
            }
        );
        return () => {
            cancelAnimationFrame(requestRef.current);
            if (gestureRecognizerRef.current) {
                gestureRecognizerRef.current.close();
            }
        };
    }, []);

    // useEffect(() => {
    //     const handler = (data: MessageData) => {
    //         // æœºå™¨è§†è§‰æ¶ˆæ¯
    //         console.log('æ¥æ”¶æœºå™¨è§†è§‰æ¶ˆæ¯:', data);
    //         const gestureRecognizerMessage = (data && JSON.parse(data.message)) as Message;
    //         setWebcamRunning(gestureRecognizerMessage.stats);
    //         if (!canvasReady) {
    //             initializeGestureRecognizer().then(() => {
    //                     enableCam()
    //                 }
    //             )
    //         }else {
    //             enableCam()
    //         }
    //
    //
    //     };
    //
    //     EventBus.subscribe("gesture", handler);
    //     return () => EventBus.unsubscribe("gesture", handler);
    // }, []);

    // å¯ç”¨/ç¦ç”¨æ‘„åƒå¤´
    const enableCam = async () => {


        if (!gestureRecognizerRef.current || !canvasReadyRef.current) {
            alert("è¯·ç­‰å¾…æ‰‹åŠ¿è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ");
            return;
        }

        if (webcamRunning) {
            setWebcamRunning(false);
            setCategoryName("");
            const stream = webcamRef.current?.srcObject as MediaStream;
            stream?.getTracks().forEach((track) => track.stop());
            return;
        }

        setWebcamRunning(true);

        // è·å–æ‘„åƒå¤´æƒé™
        const constraints = {
            video: {
                width: {ideal: 480},
                height: {ideal: 360},
                facingMode: "user"
            }
        } as MediaStreamConstraints;
        try {
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            if (webcamRef.current) {
                webcamRef.current.srcObject = stream;
            }
        } catch (err) {
            console.error("è®¿é—®æ‘„åƒå¤´å¤±è´¥:", err);
            setWebcamRunning(false);
            alert("æ— æ³•è®¿é—®æ‘„åƒå¤´ï¼Œè¯·ç¡®ä¿å·²æˆäºˆæƒé™");
        }
    };


    // æ‘„åƒå¤´é¢„æµ‹
    const predictWebcam = async () => {
        if (!webcamRunning || !gestureRecognizerRef.current || !webcamRef.current || !canvasRef.current) {
            return;
        }

        const nowInMs = Date.now();
        const video = webcamRef.current;

        // ç¡®ä¿è§†é¢‘æ—¶é—´å·²æ›´æ–°
        if (video.currentTime !== lastVideoTimeRef.current) {
            lastVideoTimeRef.current = video.currentTime;

            try {
                const results = gestureRecognizerRef.current.recognizeForVideo(video, nowInMs);

                // è·å–ç”»å¸ƒä¸Šä¸‹æ–‡ - æ·»åŠ è¯¦ç»†çš„é”™è¯¯å¤„ç†
                const canvasCtx = canvasRef.current.getContext("2d");
                if (!canvasCtx) {
                    console.error("æ— æ³•è·å–Canvas 2Dä¸Šä¸‹æ–‡");
                    console.log("canvasRef.current:", canvasRef.current);
                    console.log("canvaså°ºå¯¸:", canvasRef.current.width, "x", canvasRef.current.height);
                    return;
                }

                // è®¾ç½®ç”»å¸ƒå°ºå¯¸ä¸è§†é¢‘åŒ¹é…
                if (canvasRef.current.width !== video.videoWidth ||
                    canvasRef.current.height !== video.videoHeight) {
                    console.log("æ›´æ–°ç”»å¸ƒå°ºå¯¸")
                    console.log("canvasRef.current.width", canvasRef.current.width);
                    console.log("canvasRef.current.height", canvasRef.current.height);
                    console.log("video.videoWidth", video.videoWidth);
                    console.log("video.videoHeight", video.videoHeight);

                    canvasRef.current.width = video.videoWidth;
                    canvasRef.current.height = video.videoHeight;

                    // æ›´æ–°å®¹å™¨å°ºå¯¸
                    if (containerRef.current) {
                        console.log("æ›´æ–°å®¹å™¨å°ºå¯¸")
                        console.log("containerRef.current.style.width", containerRef.current.style.width);
                        console.log("containerRef.current.style.height", containerRef.current.style.height);
                        containerRef.current.style.width = `${video.videoWidth}px`;
                        containerRef.current.style.height = `${video.videoHeight}px`;
                    }
                }

                // æ¸…é™¤ç”»å¸ƒ

                canvasCtx.save();
                canvasCtx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);

                if (results.landmarks) {
                    const drawingUtils = new DrawingUtils(canvasCtx);
                    for (const landmarks of results.landmarks) {
                        drawingUtils.drawConnectors(landmarks, GestureRecognizer.HAND_CONNECTIONS, {
                            color: "#00FF00",
                            lineWidth: 5,
                        });
                        drawingUtils.drawLandmarks(landmarks, {
                            color: "#FF0000",
                            lineWidth: 2,
                        });
                    }
                }
                canvasCtx.restore();


                // æ˜¾ç¤ºç»“æœ
                if (results.gestures && results.gestures.length > 0 && results.gestures[0].length > 0) {
                    const categoryName = results.gestures[0][0].categoryName;
                    let categoryNameStr = "æœªçŸ¥";

                    // æ‰‹åŠ¿åç§°æ˜ å°„
                    const gestureMap: Record<string, string> = {
                        "Closed_Fist": "ç´§æ¡æ‹³å¤´",
                        "Open_Palm": "å¼ å¼€æ‰‹æŒ",
                        "Pointing_Up": "å‘ä¸ŠæŒ‡",
                        "Thumb_Up": "ç‚¹èµ",
                        "Victory": "å‰ªåˆ€æ‰‹",
                        "Thumb_Down": "é„™è§†",
                        "ILoveYou": "çˆ±ä½ å“Ÿ"
                    };

                    categoryNameStr = gestureMap[categoryName] || categoryName;
                    const categoryScore = (results.gestures[0][0].score * 100).toFixed(2);

                    // è·å–å·¦å³æ‰‹ä¿¡æ¯
                    let handedness = "æœªçŸ¥";
                    if (results.handednesses && results.handednesses.length > 0 && results.handednesses[0].length > 0) {
                        handedness = results.handednesses[0][0].displayName;
                    }
                    setCategoryName(categoryName);
                    setGestureResult(
                        `æ‰‹åŠ¿: ${categoryNameStr}\nç½®ä¿¡åº¦: ${categoryScore}%\nå·¦å³æ‰‹: ${handedness}`
                    );
                } else {
                    setGestureResult("");
                }
            } catch (error) {
                console.error("æ‰‹åŠ¿è¯†åˆ«å¤±è´¥:", error);
            }
        }

        requestRef.current = requestAnimationFrame(predictWebcam);
    };
    const emojiMap: Record<string, string> = {
        "Closed_Fist": "âœŠ",
        "Open_Palm": "ğŸ™Œ",
        "Thumb_Up": "ğŸ‘",
        "Victory": "âœŒï¸",
        "ILoveYou": "â¤ï¸"
    };
    useEffect(() => {
        if (categoryName) {
            console.log('å½“å‰æ‰‹åŠ¿:', categoryName)
            const emoji = emojiMap[categoryName];
            if (emoji) {
                onSend(emoji)
            }
        }
    }, [categoryName]);

    // å½“æ‘„åƒå¤´å¼€å§‹è¿è¡Œæ—¶çš„å¤„ç†
    useEffect(() => {
        if (webcamRunning && webcamRef.current) {
            // ç¡®ä¿è§†é¢‘å·²åŠ è½½
            if (webcamRef.current.readyState >= HTMLMediaElement.HAVE_METADATA) {
                predictWebcam();
            } else {
                webcamRef.current.onloadeddata = predictWebcam;
            }
        }
    }, [webcamRunning]);

    return (
        <div className="container">
            {/*<h1>æœºå™¨å­¦ä¹  æ‰‹åŠ¿è¯†åˆ«</h1>*/}

            {/* ä½¿ç”¨å®¹å™¨åŒ…è£¹è§†é¢‘å’Œç”»å¸ƒ */}
            <div
                ref={containerRef}
                className="webcam-container"
                style={{
                    position: 'relative',
                    width: '480px',
                    height: '360px',
                    margin: '0 auto',
                    backgroundColor: '#f0f0f0' // æ·»åŠ èƒŒæ™¯è‰²ä»¥ä¾¿è°ƒè¯•
                }}
            >
                <video
                    ref={webcamRef}
                    autoPlay
                    playsInline
                    className="webcam-video"
                    width="480"
                    height="360"
                    style={{
                        display: webcamRunning ? "block" : "none",
                        position: 'absolute',
                        top: 0,
                        left: 0,
                        width: '100%',
                        height: '100%',
                        objectFit: 'cover',
                        transform: 'scaleX(-1)' // æ°´å¹³ç¿»è½¬
                    }}
                />
                <canvas
                    ref={canvasRef}
                    className="output-canvas"
                    width="480"
                    height="360"
                    style={{
                        position: 'absolute',
                        top: 0,
                        left: 0,
                        width: '100%',
                        height: '100%',
                        zIndex: 10,
                        border: '1px solid red' // æ·»åŠ è¾¹æ¡†ä»¥ä¾¿è°ƒè¯•
                    }}
                />

                {gestureResult && (
                    <div className="gesture-output">
                        {gestureResult.split('\n').map((line, i) => (
                            <div key={i}>{line}</div>
                        ))}
                    </div>
                )}

                {/*/!* æ·»åŠ è°ƒè¯•ä¿¡æ¯ *!/*/}
                {/*<div className="debug-info">*/}
                {/*    <button*/}
                {/*        onClick={enableCam}*/}
                {/*        className="webcam-button"*/}
                {/*        disabled={!canvasReady} // åœ¨ç”»å¸ƒå‡†å¤‡å¥½ä¹‹å‰ç¦ç”¨æŒ‰é’®*/}
                {/*    >*/}
                {/*        {webcamRunning ? "ç¦ç”¨æ‘„åƒå¤´" : "å¯ç”¨æ‘„åƒå¤´"}*/}
                {/*        {!canvasReady && " (åŠ è½½ä¸­...)"}*/}
                {/*    </button>*/}
                {/*    <p>ç”»å¸ƒçŠ¶æ€: {canvasReady ? "å·²å‡†å¤‡å¥½" : "æœªå‡†å¤‡å¥½"}</p>*/}
                {/*    <p>ç”»å¸ƒå°ºå¯¸: {canvasRef.current ? `${canvasRef.current.width}x${canvasRef.current.height}` : "æœªåŠ è½½"}</p>*/}
                {/*</div>*/}
            </div>


        </div>
    );
};

export default GestureRecognizerComponent;
